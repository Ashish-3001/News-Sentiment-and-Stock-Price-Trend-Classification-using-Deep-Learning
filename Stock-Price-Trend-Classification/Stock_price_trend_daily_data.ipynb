{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching: AAPL (Apple)\n",
      "Saved AAPL data to daily_stock_chunks\\AAPL_daily.csv\n",
      "\n",
      "Fetching: MSFT (Microsoft)\n",
      "Saved MSFT data to daily_stock_chunks\\MSFT_daily.csv\n",
      "\n",
      "Fetching: AMD (AMD)\n",
      "Saved AMD data to daily_stock_chunks\\AMD_daily.csv\n",
      "\n",
      "Fetching: INTC (Intel)\n",
      "Saved INTC data to daily_stock_chunks\\INTC_daily.csv\n",
      "\n",
      "Fetching: CRM (Salesforce)\n",
      "Saved CRM data to daily_stock_chunks\\CRM_daily.csv\n",
      "\n",
      "Fetching: JPM (JPMorgan)\n",
      "Saved JPM data to daily_stock_chunks\\JPM_daily.csv\n",
      "\n",
      "Fetching: BAC (Bank of America)\n",
      "Saved BAC data to daily_stock_chunks\\BAC_daily.csv\n",
      "\n",
      "Fetching: WFC (Wells Fargo)\n",
      "Saved WFC data to daily_stock_chunks\\WFC_daily.csv\n",
      "\n",
      "Fetching: GS (Goldman Sachs)\n",
      "Saved GS data to daily_stock_chunks\\GS_daily.csv\n",
      "\n",
      "Fetching: SCHW (Charles Schwab)\n",
      "Saved SCHW data to daily_stock_chunks\\SCHW_daily.csv\n",
      "\n",
      "Fetching: GOOGL (Alphabet)\n",
      "Saved GOOGL data to daily_stock_chunks\\GOOGL_daily.csv\n",
      "\n",
      "Fetching: NVDA (NVIDIA)\n",
      "Saved NVDA data to daily_stock_chunks\\NVDA_daily.csv\n",
      "\n",
      "Fetching: ADBE (Adobe)\n",
      "Saved ADBE data to daily_stock_chunks\\ADBE_daily.csv\n",
      "\n",
      "Fetching: CSCO (Cisco Systems)\n",
      "Saved CSCO data to daily_stock_chunks\\CSCO_daily.csv\n",
      "\n",
      "Fetching: ORCL (Oracle)\n",
      "Saved ORCL data to daily_stock_chunks\\ORCL_daily.csv\n",
      "\n",
      "Fetching: QCOM (Qualcomm)\n",
      "Saved QCOM data to daily_stock_chunks\\QCOM_daily.csv\n",
      "\n",
      "Fetching: AXP (American Express)\n",
      "Saved AXP data to daily_stock_chunks\\AXP_daily.csv\n",
      "\n",
      "Fetching: C (Citigroup)\n",
      "Saved C data to daily_stock_chunks\\C_daily.csv\n",
      "\n",
      "Fetching: USB (U.S. Bancorp)\n",
      "Saved USB data to daily_stock_chunks\\USB_daily.csv\n",
      "\n",
      "Fetching: BLK (BlackRock)\n",
      "Saved BLK data to daily_stock_chunks\\BLK_daily.csv\n",
      "\n",
      "Fetching: TROW (T. Rowe Price)\n",
      "Saved TROW data to daily_stock_chunks\\TROW_daily.csv\n",
      "\n",
      "Fetching: MS (Morgan Stanley)\n",
      "Saved MS data to daily_stock_chunks\\MS_daily.csv\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# collect data from all the selected atocks and store it in CSV file\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "# This is the list of selected stock tickers\n",
    "stocks = {\n",
    "    \"AAPL\": \"Apple\",\n",
    "    \"MSFT\": \"Microsoft\",\n",
    "    \"AMD\": \"AMD\",\n",
    "    \"INTC\": \"Intel\",\n",
    "    \"CRM\": \"Salesforce\",\n",
    "    \n",
    "    \"JPM\": \"JPMorgan\",\n",
    "    \"BAC\": \"Bank of America\",\n",
    "    \"WFC\": \"Wells Fargo\",\n",
    "    \"GS\": \"Goldman Sachs\",\n",
    "    \"SCHW\": \"Charles Schwab\",\n",
    "\n",
    "    \"GOOGL\": \"Alphabet\",\n",
    "    \"NVDA\": \"NVIDIA\",\n",
    "    \"ADBE\": \"Adobe\",\n",
    "    \"CSCO\": \"Cisco Systems\",\n",
    "    \"ORCL\": \"Oracle\",\n",
    "    \"QCOM\": \"Qualcomm\",\n",
    "\n",
    "    \"AXP\": \"American Express\",\n",
    "    \"C\": \"Citigroup\",\n",
    "    \"USB\": \"U.S. Bancorp\",\n",
    "    \"BLK\": \"BlackRock\",\n",
    "    \"TROW\": \"T. Rowe Price\",\n",
    "    \"MS\": \"Morgan Stanley\"\n",
    "}\n",
    "\n",
    "chunk_days = 365 * 8\n",
    "now = datetime.now()\n",
    "start_date = now - timedelta(days=chunk_days)\n",
    "output_dir = \"daily_stock_chunks\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for ticker, company in stocks.items():\n",
    "    print(f\"\\nFetching: {ticker} ({company})\")\n",
    "    try:\n",
    "        df = yf.download(\n",
    "            ticker,\n",
    "            start=start_date.strftime('%Y-%m-%d'),\n",
    "            end=now.strftime('%Y-%m-%d'),\n",
    "            interval='1d',\n",
    "            progress=False\n",
    "        )\n",
    "        if not df.empty:\n",
    "            df = df[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "            df.insert(0, 'Date', df.index)\n",
    "            df['ticker'] = ticker\n",
    "            df['company'] = company\n",
    "            df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'ticker', 'company']]\n",
    "            path = os.path.join(output_dir, f\"{ticker}_daily.csv\")\n",
    "            df.to_csv(path, index=False)\n",
    "            print(f\"Saved {ticker} data to {path}\")\n",
    "        else:\n",
    "            print(\"No data.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# here we are trying to merge all the stock data into one csv file\n",
    "\n",
    "# we keep only the colunms from yfinance and columns  company and ticker then merger it \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "input_dir = \"daily_stock_chunks\"\n",
    "merged_dfs = []\n",
    "\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(input_dir, file))\n",
    "        df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'ticker', 'company']]\n",
    "        merged_dfs.append(df)\n",
    "\n",
    "merged_df = pd.concat(merged_dfs, ignore_index=True)\n",
    "merged_df.sort_values(by=['ticker', 'Date'], inplace=True)\n",
    "merged_df.to_csv(\"final_daily_stocks_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Done\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
